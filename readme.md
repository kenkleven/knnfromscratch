# KNN Regressor from Scratch (Python + NumPy)

Ce projet propose une impl√©mentation simple de l'algorithme **K-Nearest Neighbors (KNN)** pour la **r√©gression** et la **classification**, r√©alis√©e enti√®rement en Python avec NumPy, sans biblioth√®ques de machine learning comme scikit-learn.

## üî¢ Principe

L'algorithme KNN pour la r√©gression pr√©dit une valeur r√©elle pour un √©chantillon test en calculant la **moyenne** des valeurs cibles de ses `k` plus proches voisins dans l'ensemble d'entra√Ænement.

Formule :
\[
\hat{y} = \frac{1}{k} \sum_{i=1}^{k} y_i
\]

## üìÅ Structure du projet

- `knn_regressor.py` : contient la classe `KNNRegressor` avec :
  - `fit()`
  - `predict()`
  - `mean_squared_error()`
  - `mean_absolute_error()`
  - `r2_score()`

- `example.py` : script de test avec un jeu de donn√©es synth√©tique (`make_regression` de scikit-learn).

## ‚úÖ Fonctionnalit√©s

- M√©trique de distance : Euclidienne
- M√©triques de performance :
  - **Mean Squared Error (MSE)**
  - **Mean Absolute Error (MAE)**
  - **R¬≤ Score**

## üöÄ Exemple d'utilisation

```python
from knn_regressor import KNNRegressor
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# G√©n√©rer des donn√©es de test
X, y = make_regression(n_samples=100, n_features=1, noise=10)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Cr√©er et entra√Æner le mod√®le
model = KNNRegressor(k=5)
model.fit(X_train, y_train)

# Pr√©dictions
y_pred = model.predict(X_test)

# √âvaluation
print("MSE:", model.mean_squared_error(y_test, y_pred))
print("MAE:", model.mean_absolute_error(y_test, y_pred))
print("R¬≤ Score:", model.r2_score(y_test, y_pred))
